{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "763c6588",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-13T13:58:10.089155Z",
     "iopub.status.busy": "2023-12-13T13:58:10.088783Z",
     "iopub.status.idle": "2023-12-13T13:58:25.304950Z",
     "shell.execute_reply": "2023-12-13T13:58:25.303886Z"
    },
    "papermill": {
     "duration": 15.224941,
     "end_time": "2023-12-13T13:58:25.307112",
     "exception": false,
     "start_time": "2023-12-13T13:58:10.082171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchfile\r\n",
      "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: torchfile\r\n",
      "  Building wheel for torchfile (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5692 sha256=cab3eaa3e852b89d8730766d242de5112f3a9fa3f4a2679117fd0bc8858dec79\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c7/e9/87/1c51daf8e468d5c14931f8ac3344880f903ba96b063675cac2\r\n",
      "Successfully built torchfile\r\n",
      "Installing collected packages: torchfile\r\n",
      "Successfully installed torchfile-0.1.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a284057f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:58:25.320079Z",
     "iopub.status.busy": "2023-12-13T13:58:25.319779Z",
     "iopub.status.idle": "2023-12-13T13:58:29.312255Z",
     "shell.execute_reply": "2023-12-13T13:58:29.311413Z"
    },
    "papermill": {
     "duration": 4.001522,
     "end_time": "2023-12-13T13:58:29.314597",
     "exception": false,
     "start_time": "2023-12-13T13:58:25.313075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stage1generator', 'text-to-image-cub-200-2011']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from tensorboard import summary\n",
    "from six.moves import range\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.nn import init\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "import torch.utils.data as data\n",
    "import os.path\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.models import inception_v3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import torchfile\n",
    "\n",
    "import errno\n",
    "import torch.nn as nn\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "\n",
    "import torch.nn.parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6628a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:58:29.328445Z",
     "iopub.status.busy": "2023-12-13T13:58:29.327972Z",
     "iopub.status.idle": "2023-12-13T13:58:29.348312Z",
     "shell.execute_reply": "2023-12-13T13:58:29.347597Z"
    },
    "papermill": {
     "duration": 0.029876,
     "end_time": "2023-12-13T13:58:29.350464",
     "exception": false,
     "start_time": "2023-12-13T13:58:29.320588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_class_ids_filenames(class_id_path, filename_path):\n",
    "    with open(class_id_path, 'rb') as file:\n",
    "        class_id=pickle.load(file, encoding='latin1')\n",
    "\n",
    "    with open(filename_path, 'rb') as file:\n",
    "        filename=pickle.load(file, encoding='latin1')\n",
    "\n",
    "    return class_id, filename\n",
    "\n",
    "def load_text_embeddings(text_embeddings):\n",
    "    with open(text_embeddings, 'rb') as file:\n",
    "        embeds=pickle.load(file, encoding='latin1')\n",
    "        embeds=np.array(embeds)\n",
    "\n",
    "    return embeds\n",
    "\n",
    "def load_bbox(data_path):\n",
    "    bbox_path=data_path+'/bounding_boxes.txt'\n",
    "    image_path=data_path+'/images.txt'\n",
    "    bbox_df=pd.read_csv(bbox_path, delim_whitespace=True, header=None).astype(int)\n",
    "    filename_df=pd.read_csv(image_path, delim_whitespace=True, header=None)\n",
    "\n",
    "    filenames=filename_df[1].tolist()\n",
    "    bbox_dict={i[:-4]:[] for i in filenames[:2]}\n",
    "\n",
    "    for i in range(0, len(filenames)):\n",
    "        bbox=bbox_df.iloc[i][1:].tolist()\n",
    "        dict_key=filenames[i][:-4]\n",
    "        bbox_dict[dict_key]=bbox\n",
    "\n",
    "    return bbox_dict\n",
    "\n",
    "def load_images(image_path, bounding_box, size, transform):\n",
    "    image=Image.open(image_path).convert('RGB')\n",
    "    w, h=image.size\n",
    "    if bounding_box is not None:\n",
    "        r=int(np.maximum(bounding_box[2], bounding_box[3])*0.75)\n",
    "        c_x=int((bounding_box[0]+bounding_box[2])/2)\n",
    "        c_y=int((bounding_box[1]+bounding_box[3])/2)\n",
    "        y1=np.maximum(0, c_y-r)\n",
    "        y2=np.minimum(h, c_y+r)\n",
    "        x1=np.maximum(0, c_x-r)\n",
    "        x2=np.minimum(w, c_x+r)\n",
    "        image=image.crop([x1, y1, x2, y2])\n",
    "\n",
    "    image=image.resize(size, PIL.Image.BILINEAR)\n",
    "    if transform is not None:\n",
    "        image=transform(image)\n",
    "    return image\n",
    "\n",
    "def load_data(size, transform):\n",
    "    \"\"\"Loads the Dataset.\n",
    "    \"\"\"\n",
    "    data_dir=\"/kaggle/input/text-to-image-cub-200-2011/CUB-200-2011\"\n",
    "    train_dir=data_dir+\"/train\"\n",
    "    test_dir=data_dir+\"/test\"\n",
    "    embeddings_path_train=train_dir+\"/char-CNN-RNN-embeddings.pickle\"\n",
    "    embeddings_path_test=test_dir+\"/char-CNN-RNN-embeddings.pickle\"\n",
    "    filename_path_train=train_dir+\"/filenames.pickle\"\n",
    "    filename_path_test=test_dir+\"/filenames.pickle\"\n",
    "    class_id_path_train=train_dir+\"/class_info.pickle\"\n",
    "    class_id_path_test=test_dir+\"/class_info.pickle\"\n",
    "    if(args.TEST_OR_TRAIN=='train'):\n",
    "        class_id, filenames=load_class_ids_filenames(class_id_path_train, filename_path_train)\n",
    "        embeddings=load_text_embeddings(embeddings_path_train)\n",
    "    else:\n",
    "        class_id, filenames=load_class_ids_filenames(class_id_path_test, filename_path_test)\n",
    "        embeddings=load_text_embeddings(embeddings_path_test)\n",
    "    bbox_dict=load_bbox(data_dir)\n",
    "\n",
    "    x, y, embeds=[], [], []\n",
    "\n",
    "    for i, filename in enumerate(filenames):\n",
    "        bbox=bbox_dict[filename]\n",
    "\n",
    "        try:    \n",
    "            image_path=f'{data_dir}/images/{filename}.jpg'\n",
    "            image=load_images(image_path, bbox, size, transform)\n",
    "            e=embeddings[i, :, :]\n",
    "            embed_index=np.random.randint(0, e.shape[0]-1)\n",
    "            embed=e[embed_index, :]\n",
    "\n",
    "            x.append(np.array(image))\n",
    "            y.append(class_id[i])\n",
    "            embeds.append(embed)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'{e}')\n",
    "    \n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    embeds=np.array(embeds)\n",
    "    \n",
    "    return x, y, embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3381dcaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:58:29.363264Z",
     "iopub.status.busy": "2023-12-13T13:58:29.362968Z",
     "iopub.status.idle": "2023-12-13T13:58:29.398770Z",
     "shell.execute_reply": "2023-12-13T13:58:29.398098Z"
    },
    "papermill": {
     "duration": 0.04451,
     "end_time": "2023-12-13T13:58:29.400708",
     "exception": false,
     "start_time": "2023-12-13T13:58:29.356198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def KL_loss(mu, logvar):\n",
    "    KLD_element=mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD=torch.mean(KLD_element).mul_(-0.5)\n",
    "    return KLD\n",
    "\n",
    "def calculate_inception_score(logits):\n",
    "\n",
    "    probs=torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "    kl_div=(probs*(torch.log(probs)-torch.log(probs.mean(dim=0)))).sum(dim=1)\n",
    "    entropy=-torch.sum(probs * torch.log(probs), dim=1)\n",
    "\n",
    "    inception_score=torch.exp(torch.mean(kl_div - entropy))\n",
    "    return inception_score\n",
    "\n",
    "\n",
    "def compute_discriminator_loss(disNet, realImgs, fakeImgs, reallabels, fakelabels, conditions, gpus):\n",
    "    criterion=nn.BCELoss()\n",
    "    batch_size=realImgs.size(0)\n",
    "    cond=conditions.detach()\n",
    "    fake=fakeImgs.detach()\n",
    "    realfeatures=nn.parallel.data_parallel(disNet, (realImgs), gpus)\n",
    "    fakefeatures=nn.parallel.data_parallel(disNet, (fake), gpus)\n",
    "    inputs=(realfeatures, cond)\n",
    "    reallogits=nn.parallel.data_parallel(disNet.get_cond_logits, inputs, gpus)\n",
    "    disErr_real=criterion(reallogits, reallabels)\n",
    "    inputs=(realfeatures[:(batch_size-1)], cond[1:])\n",
    "    wrong_logits =nn.parallel.data_parallel(disNet.get_cond_logits, inputs, gpus)\n",
    "    disErr_wrong=criterion(wrong_logits, fakelabels[1:])\n",
    "    inputs=(fakefeatures, cond)\n",
    "    fakelogits=nn.parallel.data_parallel(disNet.get_cond_logits, inputs, gpus)\n",
    "    disErr_fake=criterion(fakelogits, fakelabels)\n",
    "\n",
    "    if disNet.get_uncond_logits is not None:\n",
    "        reallogits=nn.parallel.data_parallel(disNet.get_uncond_logits, (realfeatures), gpus)\n",
    "        fakelogits=nn.parallel.data_parallel(disNet.get_uncond_logits, (fakefeatures), gpus)\n",
    "        uncond_disErr_real=criterion(reallogits, reallabels)\n",
    "        uncond_disErr_fake=criterion(fakelogits, fakelabels)\n",
    "        #\n",
    "        disErr=((disErr_real+uncond_disErr_real)/2.+(disErr_fake+disErr_wrong+uncond_disErr_fake)/3.)\n",
    "        disErr_real=(disErr_real+uncond_disErr_real)/2.\n",
    "        disErr_fake=(disErr_fake+uncond_disErr_fake)/2.\n",
    "    else:\n",
    "        disErr=disErr_real+(disErr_fake+disErr_wrong)*0.5\n",
    "    return disErr, disErr_real.data, disErr_wrong.data, disErr_fake.data\n",
    "\n",
    "\n",
    "def compute_generator_loss(disNet, fakeImgs, reallabels, conditions, gpus):\n",
    "    criterion=nn.BCELoss()\n",
    "    cond=conditions.detach()\n",
    "    fakefeatures=nn.parallel.data_parallel(disNet, (fakeImgs), gpus)\n",
    "    inputs=(fakefeatures, cond)\n",
    "    fakelogits=nn.parallel.data_parallel(disNet.get_cond_logits, inputs, gpus)\n",
    "    disErr_fake=criterion(fakelogits, reallabels)\n",
    "    if disNet.get_uncond_logits is not None:\n",
    "        fakelogits=nn.parallel.data_parallel(disNet.get_uncond_logits,(fakefeatures), gpus)\n",
    "        uncond_disErr_fake=criterion(fakelogits, reallabels)\n",
    "        disErr_fake += uncond_disErr_fake\n",
    "    return disErr_fake\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname=m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "def save_img_results(data_img, fake, epoch, image_dir):\n",
    "    num=args.VIS_COUNT\n",
    "    fake=fake[0:num]\n",
    "    if data_img is not None:\n",
    "        data_img=data_img[0:num]\n",
    "        vutils.save_image(data_img, '%s/realsamples_epoch_%03d.png'%(image_dir, epoch), normalize=True)\n",
    "        vutils.save_image(fake.data, '%s/fakesamples_epoch_%03d.png'%(image_dir, epoch), normalize=True)\n",
    "    else:\n",
    "        vutils.save_image(fake.data, '%s/lr_fakesamples_epoch_%03d.png'%(image_dir, epoch), normalize=True)\n",
    "\n",
    "\n",
    "def save_model(genNet, disNet, epoch, model_dir):\n",
    "    torch.save(\n",
    "        genNet.state_dict(),\n",
    "        '%s/genNet_epoch_%d.pth'%(model_dir, epoch))\n",
    "    torch.save(\n",
    "        disNet.state_dict(),\n",
    "        '%s/disNet_epoch_last.pth'%(model_dir))\n",
    "    print('Save G/D models')\n",
    "\n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc: \n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "\n",
    "def upBlock(in_planes, out_planes):\n",
    "    block=nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "        conv3x3(in_planes, out_planes),\n",
    "        nn.BatchNorm2d(out_planes),\n",
    "        nn.ReLU(True))\n",
    "    return block\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, channel_num):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.block=nn.Sequential(\n",
    "            conv3x3(channel_num, channel_num),\n",
    "            nn.BatchNorm2d(channel_num),\n",
    "            nn.ReLU(True),\n",
    "            conv3x3(channel_num, channel_num),\n",
    "            nn.BatchNorm2d(channel_num))\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        out=self.block(x)\n",
    "        out += residual\n",
    "        out=self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class CA_NET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CA_NET, self).__init__()\n",
    "        self.t_dim=args.DIMENSION\n",
    "        self.c_dim=args.CONDITION_DIM\n",
    "        self.fc=nn.Linear(self.t_dim, self.c_dim*2, bias=True)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def encode(self, text_embedding):\n",
    "        x=self.relu(self.fc(text_embedding))\n",
    "        mu=x[:, :self.c_dim]\n",
    "        logvar=x[:, self.c_dim:]\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std=logvar.mul(0.5).exp_()\n",
    "        if args.CUDA:\n",
    "            eps=torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps=torch.FloatTensor(std.size()).normal_()\n",
    "        eps=Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def forward(self, text_embedding):\n",
    "        mu, logvar=self.encode(text_embedding)\n",
    "        c_code=self.reparametrize(mu, logvar)\n",
    "        return c_code, mu, logvar\n",
    "\n",
    "class D_GET_LOGITS(nn.Module):\n",
    "    def __init__(self, ndf, nef, bcondition=True):\n",
    "        super(D_GET_LOGITS, self).__init__()\n",
    "        self.df_dim=ndf\n",
    "        self.ef_dim=nef\n",
    "        self.bcondition=bcondition\n",
    "        if bcondition:\n",
    "            self.outlogits=nn.Sequential(\n",
    "                conv3x3(ndf*8+nef, ndf*8),\n",
    "                nn.BatchNorm2d(ndf*8),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(ndf*8, 1, kernel_size=4, stride=4),\n",
    "                nn.Sigmoid())\n",
    "        else:\n",
    "            self.outlogits=nn.Sequential(\n",
    "                nn.Conv2d(ndf*8, 1, kernel_size=4, stride=4),\n",
    "                nn.Sigmoid())\n",
    "\n",
    "    def forward(self, h_code, c_code=None):\n",
    "        if self.bcondition and c_code is not None:\n",
    "            c_code=c_code.view(-1, self.ef_dim, 1, 1)\n",
    "            c_code=c_code.repeat(1, 1, 4, 4)\n",
    "            h_c_code=torch.cat((h_code, c_code), 1)\n",
    "        else:\n",
    "            h_c_code=h_code\n",
    "\n",
    "        output=self.outlogits(h_c_code)\n",
    "        return output.view(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb0af32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:58:29.413308Z",
     "iopub.status.busy": "2023-12-13T13:58:29.413013Z",
     "iopub.status.idle": "2023-12-13T13:58:29.427899Z",
     "shell.execute_reply": "2023-12-13T13:58:29.427091Z"
    },
    "papermill": {
     "duration": 0.023473,
     "end_time": "2023-12-13T13:58:29.429853",
     "exception": false,
     "start_time": "2023-12-13T13:58:29.406380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class STAGE1_G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE1_G, self).__init__()\n",
    "        self.gf_dim=args.GF_DIM*8\n",
    "        self.ef_dim=args.CONDITION_DIM\n",
    "        self.z_dim=args.Z_DIM\n",
    "        self.define_module()\n",
    "\n",
    "    def define_module(self):\n",
    "        ninput=self.z_dim+self.ef_dim\n",
    "        ngf=self.gf_dim\n",
    "        self.ca_net=CA_NET()\n",
    "\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(ninput, ngf*4*4, bias=False),\n",
    "            nn.BatchNorm1d(ngf*4*4),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "\n",
    "        self.upsample1=upBlock(ngf, ngf//2)\n",
    "        self.upsample2=upBlock(ngf//2, ngf//4)\n",
    "        self.upsample3=upBlock(ngf//4, ngf//8)\n",
    "        self.upsample4=upBlock(ngf//8, ngf//16)\n",
    "        self.img=nn.Sequential(conv3x3(ngf//16, 3), nn.Tanh())\n",
    "\n",
    "    def forward(self, text_embedding, noise):\n",
    "        c_code, mu, logvar=self.ca_net(text_embedding)\n",
    "        z_c_code=torch.cat((noise, c_code), 1)\n",
    "        h_code=self.fc(z_c_code)\n",
    "\n",
    "        h_code=h_code.view(-1, self.gf_dim, 4, 4)\n",
    "        h_code=self.upsample1(h_code)\n",
    "        h_code=self.upsample2(h_code)\n",
    "        h_code=self.upsample3(h_code)\n",
    "        h_code=self.upsample4(h_code)\n",
    "        fakeImg=self.img(h_code)\n",
    "        return None, fakeImg, mu, logvar\n",
    "\n",
    "\n",
    "class STAGE1_D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE1_D, self).__init__()\n",
    "        self.df_dim=args.DF_DIM\n",
    "        self.ef_dim=args.CONDITION_DIM\n",
    "        self.define_module()\n",
    "\n",
    "    def define_module(self):\n",
    "        ndf, nef=self.df_dim, self.ef_dim\n",
    "        self.encode_img=nn.Sequential(\n",
    "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.get_cond_logits=D_GET_LOGITS(ndf, nef)\n",
    "        self.get_uncond_logits=None\n",
    "\n",
    "    def forward(self, image):\n",
    "        img_embedding=self.encode_img(image)\n",
    "\n",
    "        return img_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be63f044",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:58:29.442459Z",
     "iopub.status.busy": "2023-12-13T13:58:29.442183Z",
     "iopub.status.idle": "2023-12-13T13:58:29.473129Z",
     "shell.execute_reply": "2023-12-13T13:58:29.472331Z"
    },
    "papermill": {
     "duration": 0.039515,
     "end_time": "2023-12-13T13:58:29.475052",
     "exception": false,
     "start_time": "2023-12-13T13:58:29.435537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GANTrainer(object):\n",
    "    def __init__(self, output_dir):\n",
    "        if args.FLAG:\n",
    "            self.model_dir=os.path.join(output_dir, 'Model')\n",
    "            self.image_dir=os.path.join(output_dir, 'Image')\n",
    "            self.log_dir=os.path.join(output_dir, 'Log')\n",
    "            mkdir_p(self.model_dir)\n",
    "            mkdir_p(self.image_dir)\n",
    "            mkdir_p(self.log_dir)\n",
    "\n",
    "        self.max_epoch=args.MAX_EPOCH\n",
    "        self.snapshot_interval=args.SNAPSHOT_INTERVAL\n",
    "\n",
    "        s_gpus=args.GPU_ID.split(',')\n",
    "        self.gpus=[int(ix) for ix in s_gpus]\n",
    "        self.num_gpus=len(self.gpus)\n",
    "        self.batch_size=args.BATCH_SIZE*self.num_gpus\n",
    "        self.output_dir=output_dir\n",
    "        cudnn.benchmark=True\n",
    "    def stage_I_network(self):\n",
    "        genNet=STAGE1_G()\n",
    "        genNet.apply(weights_init)\n",
    "        print(genNet)\n",
    "        disNet=STAGE1_D()\n",
    "        disNet.apply(weights_init)\n",
    "        print(disNet)\n",
    "        print('***********************************************************')\n",
    "\n",
    "        if args.NET_G != '':\n",
    "            print('generator 1')\n",
    "            print('Load from: ', args.NET_G)\n",
    "        if args.NET_D != '':\n",
    "            print('discriminator 1')\n",
    "            print('Load from: ', args.NET_D)\n",
    "        if args.CUDA:\n",
    "            genNet.cuda()\n",
    "            disNet.cuda()\n",
    "        return genNet, disNet\n",
    "        \n",
    "    def stage_II_network(self):\n",
    "\n",
    "        Stage1_G=STAGE1_G()\n",
    "        genNet=STAGE2_G(Stage1_G)\n",
    "        genNet.apply(weights_init)\n",
    "        if args.NET_G != '':\n",
    "            print('Load from: ', args.NET_G)\n",
    "            state_dict = torch.load(args.NET_G,map_location=lambda storage, loc: storage)\n",
    "            genNet.load_state_dict(state_dict)\n",
    "        if args.STAGE1_G != '':\n",
    "            print('Load from: ', args.STAGE1_G)\n",
    "            state_dict = torch.load(args.STAGE1_G,map_location=lambda storage, loc: storage)\n",
    "            genNet.STAGE1_G.load_state_dict(state_dict)\n",
    "        else:\n",
    "            print(\"Please give the Stage1_G path\")\n",
    "            return\n",
    "\n",
    "        disNet=STAGE2_D()\n",
    "        disNet.apply(weights_init)\n",
    "        if args.NET_D != '':\n",
    "            print('Load from: ', args.NET_D)\n",
    "            state_dict = torch.load(args.NET_D,map_location=lambda storage, loc: storage)\n",
    "            disNet.load_state_dict(state_dict)\n",
    "\n",
    "        if args.CUDA:\n",
    "            genNet.cuda()\n",
    "            disNet.cuda()\n",
    "        return genNet, disNet\n",
    "    \n",
    "    def train(self, dataset, stage=1):\n",
    "        if stage == 1:\n",
    "            genNet, disNet=self.stage_I_network()\n",
    "        else:\n",
    "            genNet, disNet=self.stage_II_network()\n",
    "\n",
    "        nz=args.Z_DIM\n",
    "        batch_size=self.batch_size\n",
    "        noise=Variable(torch.FloatTensor(batch_size, nz))\n",
    "        fixed_noise=Variable(torch.FloatTensor(batch_size, nz).normal_(0, 1),volatile=True)\n",
    "        reallabels=Variable(torch.FloatTensor(batch_size).fill_(1))\n",
    "        fakelabels=Variable(torch.FloatTensor(batch_size).fill_(0))\n",
    "        if args.CUDA:\n",
    "            noise, fixed_noise=noise.cuda(), fixed_noise.cuda()\n",
    "            reallabels, fakelabels=reallabels.cuda(), fakelabels.cuda()\n",
    "\n",
    "        generator_lr=args.GENERATOR_LR\n",
    "        discriminator_lr=args.DISCRIMINATOR_LR\n",
    "        lr_decay_step=args.LR_DECAY_EPOCH\n",
    "        disOptimizer=optim.Adam(disNet.parameters(), lr=args.DISCRIMINATOR_LR, betas=(0.5, 0.999))\n",
    "        genNet_para=[]\n",
    "        for p in genNet.parameters():\n",
    "            if p.requires_grad:\n",
    "                genNet_para.append(p)\n",
    "        genOptimizer=optim.Adam(genNet_para,lr=args.GENERATOR_LR,betas=(0.5, 0.999))\n",
    "        count=0\n",
    "        c=0\n",
    "        fake=None\n",
    "        for epoch in range(args.START_EPOCHS, self.max_epoch):\n",
    "            torch.cuda.empty_cache()\n",
    "            print('Inside Epoch:', (epoch+1))\n",
    "            print('---------------------')\n",
    "            start_t=time.time()\n",
    "            if epoch%lr_decay_step == 0 and epoch > 0:\n",
    "                generator_lr *= 0.5\n",
    "                for param_group in genOptimizer.param_groups:\n",
    "                    param_group['lr']=generator_lr\n",
    "                discriminator_lr *= 0.5\n",
    "                for param_group in disOptimizer.param_groups:\n",
    "                    param_group['lr']=discriminator_lr\n",
    "            br=0\n",
    "            c2=0\n",
    "            for i in range(len(dataset[0])//batch_size):\n",
    "                if(i%30==0):\n",
    "                    print(\">>\", end=\" \")\n",
    "                realImg_cpu=torch.tensor(dataset[0][(i*batch_size):((i+1)*batch_size)])\n",
    "                txt_embedding=torch.tensor(dataset[2][(i*batch_size):((i+1)*batch_size)])\n",
    "                realImgs=Variable(realImg_cpu)\n",
    "                txt_embedding=Variable(txt_embedding)\n",
    "                if args.CUDA:\n",
    "                    realImgs=realImgs.cuda()\n",
    "                    txt_embedding=txt_embedding.cuda()\n",
    "                noise.data.normal_(0, 1)\n",
    "                inputs=(txt_embedding, noise)\n",
    "                _, fakeImgs, mu, logvar=nn.parallel.data_parallel(genNet, inputs, self.gpus)\n",
    "                \n",
    "                disNet.zero_grad()\n",
    "                disErr, disErr_real, disErr_wrong, disErr_fake=compute_discriminator_loss(disNet, realImgs, fakeImgs,reallabels, fakelabels, mu, self.gpus)\n",
    "                disErr.backward()\n",
    "                disOptimizer.step()\n",
    "                \n",
    "                \n",
    "                genNet.zero_grad()\n",
    "                genErr=compute_generator_loss(disNet, fakeImgs,\n",
    "                                              reallabels, mu, self.gpus)\n",
    "                kl_loss=KL_loss(mu, logvar)\n",
    "                genErr_total=genErr+kl_loss*args.KL\n",
    "                genErr_total.backward()\n",
    "                genOptimizer.step()\n",
    "                \n",
    "                br=br+1\n",
    "                \n",
    "                count=count+1\n",
    "                if(i==len(dataset[0])//batch_size-1):\n",
    "                    lr_fake, fake, _, _=nn.parallel.data_parallel(genNet, inputs, self.gpus) \n",
    "                    end_t=time.time()\n",
    "                    c=1\n",
    "                    print('''[%d/%d] Loss_D: %.4f Loss_G: %.4f Loss_KL: %.4f\n",
    "                             Loss_real: %.4f Loss_wrong:%.4f Loss_fake %.4f\n",
    "                             Total Time: %.2fsec\n",
    "                          '''\n",
    "                         %(epoch, self.max_epoch,\n",
    "                             disErr.data, genErr.data, kl_loss.data,\n",
    "                             disErr_real, disErr_wrong, disErr_fake, (end_t-start_t)))\n",
    "                    print(\"Learning Rate:\", args.DISCRIMINATOR_LR)\n",
    "            if epoch%self.snapshot_interval == 0:\n",
    "                save_model(genNet, disNet, epoch, self.model_dir)\n",
    "                save_img_results(realImg_cpu, fake, epoch, self.image_dir)\n",
    "            grid=vutils.make_grid(fake[0:args.VIS_COUNT], normalize=True, scale_each=True)\n",
    "            grid_pil=ToPILImage()(grid)\n",
    "            plt.imshow(grid_pil)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        \n",
    "        save_model(genNet, disNet, self.max_epoch, self.model_dir)\n",
    "        save_img_results(None, fake, self.max_epoch, self.image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba066fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:58:29.487323Z",
     "iopub.status.busy": "2023-12-13T13:58:29.486860Z",
     "iopub.status.idle": "2023-12-13T13:58:29.508121Z",
     "shell.execute_reply": "2023-12-13T13:58:29.507351Z"
    },
    "papermill": {
     "duration": 0.029728,
     "end_time": "2023-12-13T13:58:29.510270",
     "exception": false,
     "start_time": "2023-12-13T13:58:29.480542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STAGE2_G(nn.Module):\n",
    "    def __init__(self, STAGE1_G):\n",
    "        super(STAGE2_G, self).__init__()\n",
    "        self.gf_dim=args.GF_DIM\n",
    "        self.ef_dim=args.CONDITION_DIM\n",
    "        self.z_dim=args.Z_DIM\n",
    "        self.STAGE1_G=STAGE1_G\n",
    "            \n",
    "        for param in self.STAGE1_G.parameters():\n",
    "            param.requires_grad=False\n",
    "        self.define_module()\n",
    "\n",
    "    def _make_layer(self, block, channel_num):\n",
    "        layers=[]\n",
    "        for i in range(args.R_NUM):\n",
    "            layers.append(block(channel_num))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def define_module(self):\n",
    "        ngf=self.gf_dim\n",
    "        self.ca_net=CA_NET()\n",
    "        self.encoder=nn.Sequential(\n",
    "            conv3x3(3, ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(ngf, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(ngf*2, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True))\n",
    "        self.hr_joint=nn.Sequential(\n",
    "            conv3x3(self.ef_dim+ngf*4, ngf*4),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True))\n",
    "        self.residual=self._make_layer(ResNet, ngf*4)\n",
    "        self.upsample1=upBlock(ngf*4, ngf*2)\n",
    "        self.upsample2=upBlock(ngf*2, ngf)\n",
    "        self.upsample3=upBlock(ngf, ngf//2)\n",
    "        self.upsample4=upBlock(ngf//2, ngf//4)\n",
    "        self.img=nn.Sequential(\n",
    "            conv3x3(ngf//4, 3),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, text_embedding, noise):\n",
    "        _, stage1_img, _, _=self.STAGE1_G(text_embedding, noise)\n",
    "        stage1_img=stage1_img.detach()\n",
    "        encoded_img=self.encoder(stage1_img)\n",
    "\n",
    "        c_code, mu, logvar=self.ca_net(text_embedding)\n",
    "        c_code=c_code.view(-1, self.ef_dim, 1, 1)\n",
    "        c_code=c_code.repeat(1, 1, 16, 16)\n",
    "        i_c_code=torch.cat([encoded_img, c_code], 1)\n",
    "        h_code=self.hr_joint(i_c_code)\n",
    "        h_code=self.residual(h_code)\n",
    "\n",
    "        h_code=self.upsample1(h_code)\n",
    "        h_code=self.upsample2(h_code)\n",
    "        h_code=self.upsample3(h_code)\n",
    "        h_code=self.upsample4(h_code)\n",
    "\n",
    "        fakeImg=self.img(h_code)\n",
    "        return stage1_img, fakeImg, mu, logvar\n",
    "\n",
    "\n",
    "class STAGE2_D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE2_D, self).__init__()\n",
    "        self.df_dim=args.DF_DIM\n",
    "        self.ef_dim=args.CONDITION_DIM\n",
    "        self.define_module()\n",
    "\n",
    "    def define_module(self):\n",
    "        ndf, nef=self.df_dim, self.ef_dim\n",
    "        self.encode_img=nn.Sequential(\n",
    "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True), \n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True), \n",
    "            nn.Conv2d(ndf*8, ndf*16, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*16),\n",
    "            nn.LeakyReLU(0.2, inplace=True), \n",
    "            nn.Conv2d(ndf*16, ndf*32, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            conv3x3(ndf*32, ndf*16),\n",
    "            nn.BatchNorm2d(ndf*16),\n",
    "            nn.LeakyReLU(0.2, inplace=True), \n",
    "            conv3x3(ndf*16, ndf*8),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True)  \n",
    "        )\n",
    "\n",
    "        self.get_cond_logits=D_GET_LOGITS(ndf, nef, bcondition=True)\n",
    "        self.get_uncond_logits=D_GET_LOGITS(ndf, nef, bcondition=False)\n",
    "\n",
    "    def forward(self, image):\n",
    "        img_embedding=self.encode_img(image)\n",
    "\n",
    "        return img_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6c5f66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:58:29.522740Z",
     "iopub.status.busy": "2023-12-13T13:58:29.522103Z",
     "iopub.status.idle": "2023-12-13T13:58:29.539281Z",
     "shell.execute_reply": "2023-12-13T13:58:29.538468Z"
    },
    "papermill": {
     "duration": 0.025288,
     "end_time": "2023-12-13T13:58:29.541082",
     "exception": false,
     "start_time": "2023-12-13T13:58:29.515794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GANEval(object):\n",
    "    def __init__(self, output_dir):\n",
    "        if args.FLAG:\n",
    "            self.model_dir=os.path.join(output_dir, 'Model')\n",
    "            self.image_dir=os.path.join(output_dir, 'Image')\n",
    "            self.log_dir=os.path.join(output_dir, 'Log')\n",
    "            mkdir_p(self.model_dir)\n",
    "            mkdir_p(self.image_dir)\n",
    "            mkdir_p(self.log_dir)\n",
    "            \n",
    "        s_gpus=args.GPU_ID.split(',')\n",
    "        self.gpus=[int(ix) for ix in s_gpus]\n",
    "        self.num_gpus=len(self.gpus)\n",
    "        self.batch_size=args.BATCH_SIZE*self.num_gpus\n",
    "        self.output_dir=output_dir\n",
    "        cudnn.benchmark=True\n",
    "    \n",
    "    def stage_I_network(self):\n",
    "        genNet=STAGE1_G()\n",
    "        genNet.apply(weights_init)\n",
    "        print(genNet)\n",
    "        print('***********************************************************')\n",
    "\n",
    "        if args.STAGE1_G != '':\n",
    "            print('Generator 1')\n",
    "            print('Load from: ', args.STAGE1_G)\n",
    "            state_dict = torch.load(args.STAGE1_G,map_location=lambda storage, loc: storage)\n",
    "            genNet.load_state_dict(state_dict)\n",
    "        else:\n",
    "            print('Please provide a generator model path!')\n",
    "            return\n",
    "        if args.CUDA:\n",
    "            genNet.cuda()\n",
    "        return genNet\n",
    "    \n",
    "    def stage_II_network(self):\n",
    "\n",
    "        Stage1_G=STAGE1_G()\n",
    "        genNet=STAGE2_G(Stage1_G)\n",
    "        genNet.apply(weights_init)\n",
    "        if args.NET_G != '':\n",
    "            print('Load from: ', args.NET_G)\n",
    "            state_dict = torch.load(args.NET_G,map_location=lambda storage, loc: storage)\n",
    "            genNet.load_state_dict(state_dict)\n",
    "        else:\n",
    "            print(\"Please give NET_G path\")\n",
    "            return\n",
    "        if args.STAGE1_G != '':\n",
    "            print('Load from: ', args.STAGE1_G)\n",
    "            state_dict = torch.load(args.STAGE1_G,map_location=lambda storage, loc: storage)\n",
    "            genNet.STAGE1_G.load_state_dict(state_dict)\n",
    "        else:\n",
    "            print(\"Please give the Stage1_G path\")\n",
    "            return\n",
    "\n",
    "        if args.CUDA:\n",
    "            genNet.cuda()\n",
    "        return genNet\n",
    "    \n",
    "    def evaluate(self, dataset, stage):\n",
    "        if stage == 1:\n",
    "            genNet=self.stage_I_network()\n",
    "        else:\n",
    "            genNet=self.stage_II_network()\n",
    "\n",
    "        nz=args.Z_DIM\n",
    "        batch_size=self.batch_size\n",
    "        noise=Variable(torch.FloatTensor(batch_size, nz))\n",
    "        fixed_noise=Variable(torch.FloatTensor(batch_size, nz).normal_(0, 1),volatile=True)\n",
    "        if args.CUDA:\n",
    "            noise=noise.cuda()\n",
    "        for i in range(len(dataset[0])//batch_size):\n",
    "            if(i%30==0):\n",
    "                print(\">>\", end=\" \")\n",
    "            realImg_cpu=torch.tensor(dataset[0][(i*batch_size):((i+1)*batch_size)])\n",
    "            txt_embedding=torch.tensor(dataset[2][(i*batch_size):((i+1)*batch_size)])\n",
    "            realImgs=Variable(realImg_cpu)\n",
    "            txt_embedding=Variable(txt_embedding)\n",
    "            if args.CUDA:\n",
    "                realImgs=realImgs.cuda()\n",
    "                txt_embedding=txt_embedding.cuda()\n",
    "            noise.data.normal_(0, 1)\n",
    "            inputs=(txt_embedding, noise)\n",
    "            lr_fakeImgs, fakeImgs, mu, logvar=nn.parallel.data_parallel(genNet, inputs, self.gpus)\n",
    "            save_img_results(lr_fakeImgs, fakeImgs, i, self.image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a61ba3f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:58:29.553376Z",
     "iopub.status.busy": "2023-12-13T13:58:29.553098Z",
     "iopub.status.idle": "2023-12-13T13:58:29.567642Z",
     "shell.execute_reply": "2023-12-13T13:58:29.566770Z"
    },
    "papermill": {
     "duration": 0.023102,
     "end_time": "2023-12-13T13:58:29.569678",
     "exception": false,
     "start_time": "2023-12-13T13:58:29.546576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/\n"
     ]
    }
   ],
   "source": [
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    params=dict()\n",
    "    # Parameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "    params = dict()\n",
    "    params['CONFIG_NAME']='stageI'\n",
    "    params['DATASET_NAME']='cub'\n",
    "    params['EMBEDDING_TYPE']='cnn-rnn'\n",
    "    params['GPU_ID']='0'\n",
    "    params['CUDA']='TRUE'\n",
    "    params['WORKERS']=4\n",
    "    params['STAGE1_G']='/kaggle/input/stage1generator/netG_epoch_600.pth'\n",
    "    params['NET_G']='/kaggle/input/stage1generator/S2_genNet_epoch_250.pth'\n",
    "    params['NET_D']='/kaggle/input/stage1generator/S2_disNet_epoch_250.pth'\n",
    "    params['DATA_DIR']='../input/text-to-image-cub-200-2011/CUB-200-2011/'\n",
    "    params['IMG_DIR'] = '../input/text-to-image-cub-200-2011/CUB-200-2011/images'\n",
    "    params['VIS_COUNT']=64\n",
    "    params['Z_DIM']=100\n",
    "    params['IMSIZE']=256\n",
    "    params['STAGE']=1\n",
    "    params['FLAG']='TRUE'\n",
    "    params['BATCH_SIZE']=30\n",
    "    params['START_EPOCHS']=250\n",
    "    params['MAX_EPOCH']=370\n",
    "    params['SNAPSHOT_INTERVAL']=10\n",
    "    params['LR_DECAY_EPOCH']=20\n",
    "    params['DISCRIMINATOR_LR']=6.25e-05\n",
    "    params['GENERATOR_LR']=6.25e-05\n",
    "    params['KL']=2.0\n",
    "    \n",
    "    params['CONDITION_DIM']=128\n",
    "    params['DF_DIM']=96\n",
    "    params['GF_DIM']=192\n",
    "    params['R_NUM']=2\n",
    "    params['DIMENSION']=1024\n",
    "    params['TEST_OR_TRAIN']='test'\n",
    "    args=Struct(**params)\n",
    "    \n",
    "    manualSeed=random.randint(1, 10000)\n",
    "    random.seed(manualSeed)\n",
    "    torch.manual_seed(manualSeed)\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "    \n",
    "    output_dir='/kaggle/working/'\n",
    "    print(output_dir)\n",
    "    num_gpu=len(args.GPU_ID.split(','))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dafd216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:58:29.581874Z",
     "iopub.status.busy": "2023-12-13T13:58:29.581616Z",
     "iopub.status.idle": "2023-12-13T13:59:01.746317Z",
     "shell.execute_reply": "2023-12-13T13:59:01.745462Z"
    },
    "papermill": {
     "duration": 32.173358,
     "end_time": "2023-12-13T13:59:01.748705",
     "exception": false,
     "start_time": "2023-12-13T13:58:29.575347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if args.FLAG:\n",
    "    image_transform=transforms.Compose([\n",
    "        transforms.RandomCrop(args.IMSIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset=load_data((args.IMSIZE, args.IMSIZE), transform=image_transform)\n",
    "    assert dataset\n",
    "    dataloader=torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=args.BATCH_SIZE*num_gpu,\n",
    "        drop_last=True, shuffle=True, num_workers=int(args.WORKERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f9c5c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:59:01.761521Z",
     "iopub.status.busy": "2023-12-13T13:59:01.761205Z",
     "iopub.status.idle": "2023-12-13T13:59:15.122355Z",
     "shell.execute_reply": "2023-12-13T13:59:15.121573Z"
    },
    "papermill": {
     "duration": 13.370087,
     "end_time": "2023-12-13T13:59:15.124725",
     "exception": false,
     "start_time": "2023-12-13T13:59:01.754638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2933\n",
      "STAGE1_G(\n",
      "  (ca_net): CA_NET(\n",
      "    (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=228, out_features=24576, bias=False)\n",
      "    (1): BatchNorm1d(24576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (upsample1): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (1): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (upsample2): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (upsample3): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (upsample4): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (img): Sequential(\n",
      "    (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "***********************************************************\n",
      "Generator 1\n",
      "Load from:  /kaggle/input/stage1generator/netG_epoch_600.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26/2521106574.py:69: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  fixed_noise=Variable(torch.FloatTensor(batch_size, nz).normal_(0, 1),volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> >> >> >> "
     ]
    }
   ],
   "source": [
    "print(len(dataset[2]))\n",
    "if args.FLAG:\n",
    "    if(args.TEST_OR_TRAIN=='train'):\n",
    "        algo=GANTrainer(output_dir)\n",
    "        algo.train(dataset, args.STAGE)\n",
    "    else:\n",
    "        algo=GANEval(output_dir)\n",
    "        algo.evaluate(dataset, args.STAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b770e2d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:59:15.139059Z",
     "iopub.status.busy": "2023-12-13T13:59:15.138470Z",
     "iopub.status.idle": "2023-12-13T13:59:15.173809Z",
     "shell.execute_reply": "2023-12-13T13:59:15.172993Z"
    },
    "papermill": {
     "duration": 0.044367,
     "end_time": "2023-12-13T13:59:15.175585",
     "exception": false,
     "start_time": "2023-12-13T13:59:15.131218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3858111,
     "sourceId": 6690921,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4135742,
     "sourceId": 7185281,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30615,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 70.439571,
   "end_time": "2023-12-13T13:59:17.311626",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-13T13:58:06.872055",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
